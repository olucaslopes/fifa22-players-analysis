{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', 350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "def get_project_root_path():\n",
    "    project_directory = \"fifa22-players-analysis\"\n",
    "    separated_path = os.getcwd().split(os.sep)\n",
    "    project_directory_index = separated_path.index(project_directory) + 1\n",
    "    return os.sep.join(separated_path[0:project_directory_index])\n",
    "\n",
    "\n",
    "import joblib\n",
    "def save_model(model, model_name):\n",
    "    filename = f\"model_name_{model_name}_{str(date.today())}.pkl\"\n",
    "    print(filename)\n",
    "    model_path = os.sep.join([get_project_root_path(), \"saved_models\", filename])\n",
    "    joblib.dump(model, model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/processed_data_2022-06-26.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-3-f0e92fe96dfe>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"data/processed_data_{date.today()}.tsv\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msep\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"\\t\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhead\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\util\\_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    310\u001B[0m                 )\n\u001B[1;32m--> 311\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    312\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    313\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    678\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    679\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 680\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    681\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    682\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    573\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    574\u001B[0m     \u001B[1;31m# Create the parser.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 575\u001B[1;33m     \u001B[0mparser\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    576\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    577\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m    931\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    932\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhandles\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mIOHandles\u001B[0m \u001B[1;33m|\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 933\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    934\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    935\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1215\u001B[0m             \u001B[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1216\u001B[0m             \u001B[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1217\u001B[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001B[0m\u001B[0;32m   1218\u001B[0m                 \u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1219\u001B[0m                 \u001B[0mmode\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\io\\common.py\u001B[0m in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    787\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mencoding\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;34m\"b\"\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    788\u001B[0m             \u001B[1;31m# Encoding\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 789\u001B[1;33m             handle = open(\n\u001B[0m\u001B[0;32m    790\u001B[0m                 \u001B[0mhandle\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    791\u001B[0m                 \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'data/processed_data_2022-06-26.tsv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(f\"data/processed_data_{date.today()}.tsv\", sep=\"\\t\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def count_na(df: pd.DataFrame) -> None:\n",
    "    nan_sum = df.isna().sum()\n",
    "    display(nan_sum[nan_sum > 0])\n",
    "\n",
    "count_na(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Analisando essa tabela com os valores nulos podemos perceber que alguns jogadores do dataset não possuem um time atual, isso explica\n",
    "`wage_eur`, `club_team_id`, `club_position`, `club_jersey_number` terem a mesma quantidade de valores nulos (61),\n",
    "porém `value_eur` deveria seguir esse mesmo padrão, assim podemos dizer que 13 (74 - 61) jogadores que estão ativos não possuem um valor,\n",
    "portanto precisamos prever esses dados.\n",
    "\n",
    "Também podemos perceber que temos 2132 jogadores não possuem `pace`, `shooting`, `passing`, `dribbling`, `defending`, `physic`. Vamos analisar esses jogadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def percent_of_gk(df: pd.DataFrame) -> None:\n",
    "    gk = df[df['GK'] == 1]\n",
    "    display(gk.shape[0] / df.shape[0])\n",
    "\n",
    "\n",
    "missing_main_attr_data = data[data.pace.isna()]\n",
    "\n",
    "percent_of_gk(missing_main_attr_data)\n",
    "missing_main_attr_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Como vimos que os goleiros não tem os atributos listados acima, mas possuem um overall em cada posição, seria interessante prever esses atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "missing_gk_speed_data = data[data.goalkeeping_speed.isna()]\n",
    "sum_of_missing_data = missing_gk_speed_data.shape[0] + missing_main_attr_data.shape[0]\n",
    "print(f\"Jogadores sem gk speed + jogadores sem atributos primários: {sum_of_missing_data}\")\n",
    "print(f\"Numero de jogadores: {data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Assim podemos ver que todos os jogadores que não são goleiros não possuem `goalkeeping_speed`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Prevendo valor dos jogadores\n",
    "Nessa etapa vamos criar um modelo para prever o valor dos 13 jogadores que não possuem valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "def predict_and_populate(df_to_populate, df_to_train, model, column_to_predict, round_=None, save=False) -> pd.DataFrame:\n",
    "    # Separating the target variable\n",
    "    target = df_to_train[column_to_predict]\n",
    "    features = df_to_train.drop(column_to_predict, axis=1)\n",
    "\n",
    "    # Poluting the missing features\n",
    "    mean_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    mean_imputer.fit(features)\n",
    "    imputed_features = mean_imputer.transform(features)\n",
    "\n",
    "    # Using RFECV to select best features\n",
    "    rfecv = RFECV(estimator=model, step=1, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "    rfecv_feats = rfecv.fit(imputed_features, target)\n",
    "\n",
    "\n",
    "    # Train test split\n",
    "    features_train, features_test, target_train, target_test = train_test_split(rfecv_feats, target, test_size=0.2)\n",
    "\n",
    "    # Training the model\n",
    "    trained_model = model.fit(features_train, target_train)\n",
    "\n",
    "    # Saving the model\n",
    "    if save:\n",
    "        model_name = str(model).split(\"(\")[0]\n",
    "        filename = f\"{model_name}_{column_to_predict}\"\n",
    "        save_model(trained_model, filename)\n",
    "\n",
    "    # Calculating model score\n",
    "    model_score = trained_model.score(features_test, target_test)\n",
    "    print(f\"Score do R² modelo: {model_score:.4f}\")\n",
    "\n",
    "\n",
    "    if model == linear_regression or DummyRegressor:\n",
    "        mse = mean_squared_error(target_test, trained_model.predict(features_test))\n",
    "        mae = mean_absolute_error(target_test, trained_model.predict(features_test))\n",
    "        print(f\"MSE: {mse:.4f}\")\n",
    "        print(f\"MAE: {mae:.4f}\")\n",
    "    elif model == RandomForestRegressor:\n",
    "        mse = mean_squared_error(target_test, trained_model.predict(features_test))\n",
    "        rmse = np.sqrt(mse)\n",
    "        print(f\"MSE: {mse:.4f}\")\n",
    "        print(f\"RMSE: {rmse:.4f}\")\n",
    "\n",
    "    # Populating the missing values\n",
    "    feature_to_populate = mean_imputer.transform(df_to_populate.drop(column_to_predict, axis=1))\n",
    "    predicted_values = trained_model.predict(feature_to_populate)\n",
    "\n",
    "\n",
    "    if round_ is not None:\n",
    "        predicted_values = predicted_values.round(round_)\n",
    "\n",
    "    df_to_populate[column_to_predict] = predicted_values\n",
    "\n",
    "    return df_to_populate\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "players_with_club_and_no_value = data.query(\"not club_team_id.isna() and value_eur.isna()\").copy()\n",
    "data_without_players_with_club_and_no_value = data.drop(players_with_club_and_no_value.index)\n",
    "\n",
    "data_to_train = data_without_players_with_club_and_no_value.query(\"not value_eur.isna()\").copy()\n",
    "columns_to_drop = [\n",
    "    \"sofifa_id\", \"player_url\", \"short_name\", \"long_name\",\n",
    "    \"dob\", \"club_position\",\"player_traits\", \"player_tags\",\n",
    "    \"player_positions\", \"work_rate\", \"body_type\",\n",
    "    \"preferred_foot\", \"nationality_name\"\n",
    "]\n",
    "\n",
    "data_to_train = data_to_train.drop(columns=columns_to_drop)\n",
    "data_to_fill = players_with_club_and_no_value.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Normalizando os dados\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "#\n",
    "# standerd_scaler =  StandardScaler()\n",
    "# standardized_features = standerd_scaler.fit_transform(imputed_features)\n",
    "# standardized_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Comparando modelos diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO ver tanto o MSE quanto o MAE\n",
    "# TODO aplicar RFECV em cada modelo\n",
    "\n",
    "from sklearn.dummy import DummyRegressor\n",
    "dummy = DummyRegressor()\n",
    "predict_and_populate(data_to_fill, data_to_train, dummy, \"value_eur\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_regression = LinearRegression()\n",
    "predict_and_populate(data_to_fill, data_to_train, linear_regression, \"value_eur\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "random_forest = RandomForestRegressor(random_state=0, n_jobs=-1, oob_score=True)\n",
    "players_with_club_and_no_value = predict_and_populate(\n",
    "    data_to_fill, data_to_train, random_forest, \"value_eur\", save=True\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Preenchendo os dados a partir do modelo criado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.loc[players_with_club_and_no_value.index, \"value_eur\"] = players_with_club_and_no_value.value_eur\n",
    "data.loc[players_with_club_and_no_value.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "count_na(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Removendo jogadores não ativos\n",
    "data = data.query(\"not club_team_id.isna()\").copy()\n",
    "\n",
    "count_na(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Prevendo pace, shooting, passing, dribbling, defending, physic dos goleiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gk_data = data.query(\"GK == 1\").copy()\n",
    "data_without_gk = data.query(\"GK == 0\").copy()\n",
    "\n",
    "columns_to_predict = [\"pace\", \"shooting\", \"passing\", \"dribbling\", \"defending\", \"physic\"]\n",
    "\n",
    "for column_to_predict in columns_to_predict:\n",
    "\n",
    "    columns_to_drop_with_other_atributes = [col for col in columns_to_predict if col != column_to_predict]\n",
    "    columns_to_drop_with_other_atributes.extend(columns_to_drop)\n",
    "\n",
    "    data_to_train = data_without_gk.drop(columns=columns_to_drop_with_other_atributes)\n",
    "    data_to_predict = gk_data.drop(columns=columns_to_drop_with_other_atributes)\n",
    "\n",
    "    linear_regression = LinearRegression()\n",
    "    print(f\"Prevendo {column_to_predict}\")\n",
    "    filled_data = predict_and_populate(\n",
    "        data_to_predict, data_to_train, linear_regression,\n",
    "        column_to_predict, 0, save=True\n",
    "    )\n",
    "    print()\n",
    "\n",
    "    data.loc[filled_data.index, column_to_predict] = filled_data[column_to_predict]\n",
    "\n",
    "# data.loc[gk_data.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "count_na(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Prevendo goalkeeping_speed dos jogadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "players_data = data.query(\"GK == 0\").copy()\n",
    "players_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_to_predict = players_data.drop(columns=columns_to_drop)\n",
    "data_to_train = gk_data.drop(columns=columns_to_drop)\n",
    "\n",
    "column_to_predict = \"goalkeeping_speed\"\n",
    "\n",
    "linear_regression = LinearRegression()\n",
    "filled_data = predict_and_populate(\n",
    "    data_to_predict, data_to_train, linear_regression, column_to_predict, 0, save=True\n",
    ")\n",
    "\n",
    "data.loc[filled_data.index, column_to_predict] = filled_data[column_to_predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "count_na(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "data.drop(columns=[\"release_clause_eur\"], inplace=True)\n",
    "\n",
    "filled_data_save_path = os.sep.join([get_project_root_path(), \"preprocessing\", \"data\", f\"filled_data_{date.today()}.tsv\"])\n",
    "data.to_csv(filled_data_save_path, index=False, sep=\"\\t\")\n",
    "filled_data_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "count_na(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.describe().T.round()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}